---
title:
  - "![](./Imagen_logo_ITAM.jpg){width=10in}"
  - <center><h1><div class="green"> **PRÁCTICA FINAL METODOS BAYESIANOS** </div></h1><center>
  - <center><h1><div class="green"> PRIMAVERA 2021 </div></h1><center>
  - "![](./Imagen_espacio.jpg){width=10in}"
author:
  - <center><h1><div class="darkgreen"> **EQUIPO 08** </div></h1><center>
  - <center> <font size="5"> Dorely Morales Santiago  178095 </font> <center>
  - <center> <font size="5"> Rodrigo Suárez Segovia   191351 </font> <center>
  - <center> <font size="5"> Zarazúa Cruz Guillermo   159396 </font> <center>
date:
  - "![](./Imagen_espacio.jpg){width=10in}"
output:
  html_document: default
---

<!-- Justificamos el texto -->
<style>
body {
text-align: justify}
</style>

```{r, echo=FALSE}
# Función para dar color al texto que se pasa como parámetro
colorize <- function(texto, color1="#FFFFFF", subtitle=FALSE, color2='LightSeaGreen') {
if (knitr::is_html_output()) {
    if(subtitle==FALSE)
      sprintf("<span style='color: %s;'>%s</span>", color1, texto)
    else
      sprintf("<br/><br/><mark style='color: %s; background-color: %s'>%s</mark><br/><br/>", color1, color2, texto)
      # sprintf("<span style='background-color: %s;'>%s</span>", color2, texto ) # con <span> no reslata el texto
  }
}

# Función para enmarcar texto en cuadro de color
col_square <- function(texto, color1="#00614E", color2="#FFFFFF"){
  if(knitr::is_html_output()){
    sprintf("<br/><br/><div style='text-align: left; border: 10px solid %s; font-weight:normal; font-size: 35px; background-color: %s; color: %s;'> %s </div><br/><br/>",color1,color1,color2,texto)
  }
}

```

**Entrega:** 

Enviar por correo electrónico una carpeta comprimida
(`equipo-xx.zip`) que incluya datos y codigo de solución a mas tardar el 18 de
Mayo antes de las 11:59pm (medianoche). El asunto deberá ser `[MB - 2021]
Final Equipo XX`, donde  reemplazarás `XX` con el codigo de tu equipo. No se
aceptarán entregas extemporáneas. Será mejor entregar un examen resuelto
parcialmente, que no entregar nada. 

**Instrucciones:**
  
* Tus respuestas deben ser claras y debes explicar los resultados, incluye
también tus procedimientos/código de manera ordenada, y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas,
...).

* Las sesión del Martes 11 de Mayo será destinada a responder dudas del
examen. Para esto se reservará una media hora para dudas (dependerá de la agenda
cuál será el momento mas oportuno para abrir el espacio). 

* Se podrá usar el foro de discusión para realizar preguntas y afinar detalles 
que no queden claros. 

* No pueden compartir soluciones entre diferentes equipos.

* Al entregar este examen afirmas que el trabajo se realizó sólo con tu
compañeros de equipo. El material que utilizaste para apoyarte consistió de las
notas en clase (pdfs en Canvas), el codigo fuente de las notas en el repositorio
de Github.

* Al entregar estás dando tu consentimiento para que bajo sospecha y suficiente
evidencia de copia se anule tu evaluación.

* La carpeta comprimida deberá incluir la resolución del examen también en
formato `.html`. La evaluación será completamente sobre el `html` y el código
fuente será utilizado para verificar detalles adicionales. Si el `html` no
incluye alguna sección de la evaluación se tomará dicha sección como **no
entregado**.

**Ponderación:**

El examen está compuesto por cuatro apartados cuyos pesos son los siguientes:  
- Águilas    (15\%),  
- Huracanes  (45\%),  
- Omega-3    (15\%),  
- Vacas      (25\%).  

```{r setup, include=FALSE}
library(tidymodels)
library(tidyverse)
library(cmdstanr)
library(rstanarm)
library(bayesplot)
library(loo)

library(patchwork)
library(scales)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE, 
                      fig.align = 'center', fig.width = 5, fig.height=3, cache = TRUE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_linedraw())

SEED <- 2021 #proponemos una semilla para reproducibilidad
set.seed(SEED) 
```

```{r}
sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
sin_leyenda <- theme(legend.position = "none")
sin_ejes <- theme(axis.ticks = element_blank(), 
                  axis.text = element_blank())
```


```{r, warning=FALSE, message=FALSE, echo=T, results='hide'}
# Carga de las librerias adicionales utilizadas por el Equipo 8

# Librería:             Funciones utilizadas:
# summarytools          dfSummary
# latex2exp             TeX
# MASS                  Base de datos eagles
# kableExtra            Formato tablas (html)
# tidybayes             
# rethinking            Base de datos Hurricanes
# brms                  modelos binomiales

# Creamos una lista con las librerías, luego obtenemos las que no se tienen
# instaladas, luego instalamos las que hagan falta
lib_proy <- c('summarytools','latex2exp', 'MASS', 'kableExtra', 'tidybayes', 'brms', 'ggplot2')
lib_proy_faltantes <- lib_proy[!(lib_proy %in% installed.packages()[ , "Package"])]
if(length(lib_proy_faltantes)) install.packages(lib_proy_faltantes)

# Para instalar la librería "rethinking" usar los siguientes comandos:
# install.packages(c("coda","mvtnorm","devtools","loo","dagitty")) #CHECAR SI ESTE ES NECESARIO
# devtools::install_github("rmcelreath/rethinking")

# Cargamos todas las librerías
lapply(c(lib_proy, 'rethinking'), require, character.only = TRUE)


# Los modelos se guardarán en la carpeta fits, la cual debe existir donde está el este .Rmd
# La siguiente línea checa si existe dicha carperta, y si no la crea.
dir.create(file.path(getwd(), 'fits'), showWarnings = FALSE)

```


`r col_square("**1.** Modelos de conteo: Águilas")`

Los datos contenidos en `MASS` (eagles) son registros intento de robo entre
águilas blancas en el estado de Washington. Ve la ayuda para mayor detalle en el
conjunto de datos:

```{r, warning=FALSE, message=FALSE, cache = TRUE, results='markup', eval=FALSE}
data(eagles)

#?eagles
eagles %>%
  kbl(digits=2, format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

```{r, warning=FALSE, message=FALSE, cache = TRUE, eval=FALSE}
descr(eagles) %>%
  kbl(digits=2, format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

```{r, warning=FALSE, message=FALSE, cache = TRUE, results='asis'}
# Si se quisiera visualizar el summary corriendo solo este chunck hacerlo con:
# print(dfSummary(eagles, plain.ascii=FALSE, style="grid", valid.col=FALSE), method="render")

# Con lo sisuientes parámetros (incluido la opción del chunk "results='asis'", puede
# visualizarse el summary cuando se genera el html)
dfSummary(eagles, plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, valid.col = FALSE, tmp.img.dir = "/tmp")
```


Mientras un águila se alimenta, a veces otra se abalanza y trata de robar el
salmón. Llamemos al águila que se está alimentando la "víctima" y al ladrón el
"pirata". Utiliza los datos disponibles para construir un GLM binomial para
predecir los intentos exitosos de piratería.

## `r colorize("Inciso  **1.a**   ", subtitle=TRUE)`

Considera el modelo:

$$
\begin{align}
y_i &\sim \textsf{Binomial}(n_i, p_i) \,,\\
\textsf{logit}(p_i) &= \alpha + \beta_P P_i + \beta_V V_i + \beta_A A_i\,,\\
\alpha &\sim \textsf{N}(0, 1.5) \,,\\
\beta_P, \beta_V, \beta_A &\sim \mathsf{N}(0, 0.5) \,,
\end{align}
$$
donde $y$ es el número de intentos exitosos, $n$ es el número total de intentos,
$P$ es una variable ficticia que indica si el pirata tenía un tamaño corporal
grande o no, $V$ es una variable ficticia que indica si la víctima tenía o no un
tamaño corporal grande, y finalmente $A$ es una variable ficticia que indica si
el pirata era o no un adulto. Ajusta el modelo anterior a los datos de las
águilas con la herramienta de tu preferencia e interpreta las estimaciones. 


## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

```{r, message=FALSE, cache = TRUE}
# Guardamos el dataset en otra variable para agregar unas variables
aguilas <- eagles
# Creamos variables indicadoras (dummies) para las varaibles asociadas a los atributos del ave pirata y víctima,
# con la finalidad de poderlo meter así al modelo
aguilas$pirataGrande <- ifelse(aguilas$P == "L", 1, 0)
aguilas$victimaGrande <- ifelse(aguilas$V == "L", 1, 0)
aguilas$pirataAdulto <- ifelse(aguilas$A == "A", 1, 0)
```

```{r, message=FALSE, cache = TRUE}
fit_1a<-brm(data=aguilas,
            family = binomial,
            y | trials(n) ~ 1 + pirataGrande + victimaGrande + pirataAdulto, #el evento si el robo fue exitoso como una binomial condicionada en el número de intentos
            prior = c(prior(normal(0, 1.5), class = Intercept),
                      prior(normal(0, 0.5), class = b)),
            seed=SEED,
            sample_prior = T, #pedimos muestras de la previa
            file = "fits/aguilas.fit1a")

summary(fit_1a, digits = 2)
```


```{r, message=FALSE, cache = TRUE}
print(fit_1a) #imprimimos el objeto con el modelo
```


```{r, message=FALSE, cache = TRUE}
# Una forma alternativa para ajustar el modelo es con la función "ulam" de la librería de "rethinking"

# Definimos el modelo
f <- alist(
  y ~ dbinom(n, p),
  logit(p) <- a + bP*pirataGrande + bV*victimaGrande + bA*pirataAdulto,
  a ~ dnorm(0, 1.5),
  bP ~ dnorm(0, .5),
  bV ~ dnorm(0, .5),
  bA ~ dnorm(0, .5)
)

# Ajustamos un modelo con la función "ulam" (Hamiltonian Monte Carlo with)
fit_1a_2 <- ulam(f, data = aguilas, chains = 4, log_lik = TRUE) #fit_1a_2 object itself is in the @stanfit slot. Anything you'd do with a Stan model can be done with that slot directly
```


## `r colorize("Inciso  **1.b**", subtitle=TRUE)`

Luego grafica las predicciones posteriores. Para esto calcula y muestra
tanto: 1) la predicción de la probabilidad de éxito y su intervalo de
credibilidad de 89\% para cada observación en los datos; como: 2) el número de
éxitos y su intervalo del 89\%. ¿Qué información proporciona cada tipo de
predicción posterior?

## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

```{r, message=FALSE, cache = TRUE}
probas_y_no_exitos <- setNames(data.frame(matrix(ncol = 6, nrow = 8)), c("p_mean", "p_li_0.055", "p_ls_0.945", "ne_mean", "ne_li_0.055", "ne_ls_0.945"))
rownames(probas_y_no_exitos) <- paste(aguilas$P,aguilas$A,aguilas$V)

simulacion_coeficientes <- as.matrix(posterior_samples(fit_1a)[,1:4]) # Fijas semilla (obtiene 4000)
posibles_resultados <- as.matrix(cbind(rep(1,8),aguilas[1:8,c(6,7,8)]))
simulacion_probas <- logistic(simulacion_coeficientes%*%t(posibles_resultados))

probas_y_no_exitos$p_mean <- apply(X = simulacion_probas, MARGIN = 2, FUN = mean)
probas_y_no_exitos[,c("p_li_0.055","p_ls_0.945")] <- t(apply(X = simulacion_probas, MARGIN = 2, FUN = PI, prob=c(0.89)))

# Para obtener la media, error e intervalos de confianza de las simulacion de la posteriro puede ejecutarse: predict(fit_1a)
# Para obtener todas las simulaciones de la posterior (4000) (con las cuales se pueden obtener los resultados de predit(fit_1a))
aux<-posterior_predict(fit_1a) # recordar fijar semilla (obtiene 1000)
probas_y_no_exitos$ne_mean <- apply(X=aux, MARGIN=2, FUN=mean)
probas_y_no_exitos[,c("ne_li_0.055","ne_ls_0.945")] <- t(apply(X = aux, MARGIN = 2, FUN = PI, prob=c(0.89)))

probas_y_no_exitos
```



```{r, message=FALSE, cache = TRUE}
ggplot(probas_y_no_exitos, aes(x = rownames(probas_y_no_exitos), y = p_mean)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = p_li_0.055, ymin = p_ls_0.945)) +
  sin_lineas
```

```{r, message=FALSE, cache = TRUE,fig.width=12, fig.height=5}
g1<-ggplot(probas_y_no_exitos, aes(x = paste(rownames(probas_y_no_exitos), " n=", aguilas$n), y = ne_mean)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = ne_li_0.055, ymin = ne_ls_0.945), axis.text.x = element_text(vjust=1)) +
  sin_lineas +
  theme(text = element_text(size=20), plot.title=element_text(hjust=0.5)) +
  ggtitle("Intervalos de confianza al 89% Numero de Exitos") +
  xlab("Posibles combinaciones de atributos aguilas pirata y victima") + ylab("No. exitos condicionado a n intentos")
g1
```

```{r, message=FALSE, cache = TRUE}
probas_y_no_exitos <- setNames(data.frame(matrix(ncol = 6, nrow = 8)), c("p_mean", "p_li_0.055", "p_ls_0.945", "ne_mean", "ne_li_0.055", "ne_ls_0.945"))
rownames(probas_y_no_exitos) <- paste(aguilas$P,aguilas$A,aguilas$V)


post <- extract.samples(fit_1a_2) # Fijas semilla (obtiene 2000)
simulacion_coeficientes <- as.matrix(cbind(post$a,post$bP, post$bV, post$bA)[1:2000,1:4])
posibles_resultados <- as.matrix(cbind(rep(1,8),aguilas[1:8,c(6,7,8)]))
simulacion_probas <- logistic(simulacion_coeficientes%*%t(posibles_resultados))

probas_y_no_exitos$p_mean <- apply(X = simulacion_probas, MARGIN = 2, FUN = mean)
probas_y_no_exitos[,c("p_li_0.055","p_ls_0.945")] <- t(apply(X = simulacion_probas, MARGIN = 2, FUN = PI, prob=c(0.89)))

aux<-sim(fit_1a_2) # recordar fijar semilla (obtiene 1000)
probas_y_no_exitos$ne_mean <- apply(X=aux, MARGIN=2, FUN=mean)
probas_y_no_exitos[,c("ne_li_0.055","ne_ls_0.945")] <- t(apply(X = aux, MARGIN = 2, FUN = PI, prob=c(0.89)))


probas_y_no_exitos
```

```{r, message=FALSE, cache = TRUE}
ggplot(probas_y_no_exitos, aes(x = rownames(probas_y_no_exitos), y = p_mean)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = p_li_0.055, ymin = p_ls_0.945)) +
  sin_lineas
```

```{r, message=FALSE, cache = TRUE}
ggplot(probas_y_no_exitos, aes(x = paste(rownames(probas_y_no_exitos), " n=", aguilas$n), y = ne_mean)) +
  geom_point(size = 4) +
  geom_errorbar(aes(ymax = ne_li_0.055, ymin = ne_ls_0.945)) +
  sin_lineas
```

## `r colorize("Inciso  **1.c**", subtitle=TRUE)`

Ahora intenta mejorar el modelo. Considera una interacción entre el tamaño y
edad de los piratas. Compara la capacidad predictiva de los modelos. Interpreta
los resultados.

## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

Utilizaremos brm para el fit del modelo

```{r, message=FALSE, cache = TRUE}
fit_1c<-brm(data=aguilas,
            family = binomial,
            y | trials(n) ~ 1 + pirataGrande+victimaGrande+pirataAdulto+pirataGrande:pirataAdulto, #el evento si el robo fue exitoso como una binomial condicionada en el número de intentos
            prior = c(prior(normal(0, 1.5), class = Intercept),
                      prior(normal(0, 0.5), class = b)),
            seed=SEED,
            sample_prior = T, #pedimos muestras de la previa
            file = "fits/aguilas.fit1c")
summary(fit_1c, digits = 2)
```


```{r, message=FALSE, cache = TRUE}
waic_1a<-waic(fit_1a) #calcula: elpd_waic que corresponde a la log-densidad; p_waic: el número efectivo de parámetros; waic: la devianza del modelo así como suss errores estándar variando sobre todas las observaciones
waic_1c<-waic(fit_1c) #calcula: elpd_waic que corresponde a la log-densidad; p_waic: el número efectivo de parámetros; waic: la devianza del modelo así como suss errores estándar variando sobre todas las observaciones
comparativo_waic_1c<-cbind(waic_1a,waic_1c) #combina resultados para comparar
comparativo_waic_1c
```

Y los resultados arrojan que el modelo del inciso a) y c) (con y sin interacción respectivamente) tienen un desempeño prácticamente igual ya que la devianza es prácticamente igual 59.16 en contraste con 60.68.

Luego generamos un comparativo en términos de la log-densidad predictiva con el método loo_compare().

```{r, message=FALSE, cache = TRUE}
comparativo_diff_waic_1c<-loo_compare(waic_1a,waic_1c) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_waic_1c #imprime comparativo
```

Estos resultados si bien identifican al modelo del inciso a como el mejor pues tiene una mayor log-densidad predictiva. En realidad se aprecia una diferencia mínima en la log-densidad predictiva y el error estándar del modelo c) con respecto al del inciso a).

Por último comparamos los modelos con validación cruzada mediante la función loo():

```{r, message=FALSE, cache = TRUE}
loo_1a<-loo(fit_1a) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1a #imprime resultados 
```

```{r, message=FALSE, cache = TRUE}
loo_1c<-loo(fit_1c) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_1c #imprime resultados 
```
En ambos casos, el diagnóstico que loo arroja es que ambos modelos son malos! REVISAR

```{r, message=FALSE, cache = TRUE}
comparativo_diff_loo_1c<-loo_compare(loo_1a,loo_1c) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_1c #imprime comparativo
```

SOLUCIÓN: Jup, there’s not really much of a difference here. For the interaction model: the log-odds of successful piracy is just weakly bigger when the pirating individual is large and an adult. That is counter-intuitive, isn’t it? It is worth pointing out that the individual parameters for these conditions show the expected effects and the identified negative effect of their interaction may be down to the sparsity of the underlying data and we are also highly uncertain of it’s sign to begin with.



```{r, message=FALSE, cache = TRUE}
fit_1c_2 <- ulam(
  alist(
    y ~ dbinom(n, p),
    logit(p) <- a + bP*pirataGrande + bV*victimaGrande + bA*pirataAdulto + bPA*pirataGrande*pirataAdulto,
    a ~ dnorm(0, 1.5),
    bP ~ dnorm(0, .5),
    bV ~ dnorm(0, .5),
    bA ~ dnorm(0, .5),
    bPA ~ dnorm(0, .5)
  ),
  data = aguilas, chains = 4, log_lik = TRUE
)
```

```{r, message=FALSE, cache = TRUE}
#compare(fit_1a_2, fit_1c_2)
```


```{r}
# plot(coeftab(mH3ulam, mH3c),
#   labels = paste(rep(rownames(coeftab(mH3ulam, mH3c)@coefs), each = 2),
#     rep(c("Base", "Interac"), nrow(coeftab(mH3ulam, mH3c)@coefs) * 2),
#     sep = "-"
#   )
# )
```



`r col_square("**2.** Extensiones de modelos de conteo: huracanes")`

En 2014, se publicó un artículo titulado [*"Female hurricanes are deadlier than
male hurricanes"*](https://www.pnas.org/content/111/24/8782). Como sugiere el
título, el documento afirmó que los huracanes con nombres femeninos han causado
una mayor pérdida de vidas, y la explicación que se da es que las personas
inconscientemente califican a los huracanes femeninos como menos peligrosos y,
por lo tanto, es menos probable que se necesite evacuar. Los estadísticos
criticaron duramente el artículo después de su publicación. En esta sección,
explorarás los datos completos utilizados en el artículo y considerarás la
hipótesis que los huracanes con nombres femeninos son más letales. Carga los
datos con:


```{r, warning=FALSE, message=FALSE, cache = TRUE, results='markup'}
data(Hurricanes)

Hurricanes %>%
  head() %>%
  kbl(digits=2, format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

```{r, warning=FALSE, message=FALSE, cache = TRUE}
descr(Hurricanes) %>%
  kbl(digits=2, format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


```{r, warning=FALSE, message=FALSE, cache = TRUE, results='asis'}
# Si se quisiera visualizar el summary corriendo solo este chunck hacerlo con:
# print(dfSummary(Hurricanes, plain.ascii=FALSE, style="grid", valid.col=FALSE), method="render")

# Con lo sisuientes parámetros (incluido la opción del chunk "results='asis'", puede
# visualizarse el summary cuando se genera el html)
dfSummary(Hurricanes, plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, valid.col = FALSE, tmp.img.dir = "/tmp")
```

Familiarízate con las columnas inspeccionando la ayuda `?Hurricanes`. En este
problema, te concentrarás en predecir muertes usando la feminidad de cada nombre
del huracán. 

## `r colorize("Inciso  **2.a**", subtitle=TRUE)`

Ajustaremos e interpretaremos el modelo más simple posible, un
modelo de Poisson de muertes utilizando la feminidad como predictor. 
Compara el modelo a un modelo de muertes Poisson con sólo
intercepto. ¿Qué tan fuerte es la asociación entre la feminidad del nombre y el
número de muertes? ¿Qué tormentas ajustan bien con el modelo? ¿Qué tormentas son
las que no son tan fáciles de predecir?

## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

1. name : Nombre del Huracán
2. year : Año del Huracán
3. deaths : Número de muertes
4. category : Severidad del fenómeno
5. min_pressure : Presión mínima, un indicador de fuerza de la tormenta; entre más bajo, más fuerte
6. damage_norm : Estimación Normalizada del daño en dólares
7. female : Variable indicadora de si el nombre del huracán tiene género mujer (1) u hombre (0)
8. femininity : en escala de 1 a 11, 
1-11 scale from totally masculine (1) to totally feminine (11) for name. Average of 9 scores from 9 raters.

Ajustamos un modelo de Poisson de muertes a partir de la feminidad. Primero centramos la variable de feminidad alrededor de su media para poder dar una interpretación más sencilla al modelo para predecir el número de muertes:

El punto de referencia, por tanto, parte del score de feminidad promedio en los huracanes que es de:

```{r}
# Guardamos el dataset en otra variable para agregar unas variables
huracanes <- Hurricanes
round(mean(huracanes$femininity),1)
```

```{r, message=FALSE, cache = TRUE}
feminidad.centrada<-as.data.frame(scale(huracanes$femininity,scale = FALSE)) #centramos feminidad alrededor de su media
colnames(feminidad.centrada)<-c("feminidad.centrada") #la nombramos feminidad.centrada
huracanes<-cbind(huracanes,feminidad.centrada) #integramos las variables en menores.edad

head(huracanes) #imprimimos las primeras observaciones
```

Ahora ya podemos proceder a ajustar el modelo:

```{r}
fit_2a<-brm(data=huracanes,
            family=poisson,
            deaths~ 1 + feminidad.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2a")

summary(fit_2a, digits = 2)
```

De lo anterior, encontramos que la feminidad.centrada tiene un efecto positivo sobre el número de muertes cuando este valor se incrementa con respecto a la media.

```{r}
plot(conditional_effects(fit_2a, effects = "feminidad.centrada"))
```

```{r}
prior_summary(fit_2a)
```




A continuación ajustamos el modelo de muertes Poisson con sólo intercepto para comparar.

```{r}
fit_2a1<-brm(data=huracanes,
            family=poisson,
            deaths~ 1,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2a1")

summary(fit_2a1, digits = 2)
```


```{r}
prior_summary(fit_2a1)
```

Y vemos que el coeficiente del intercepto incrementa un poco. Vamos a comparar ambos modelos a continuación:

¿Qué tan fuerte es la asociación entre la feminidad del nombre y el
número de muertes? ¿Qué tormentas ajustan bien con el modelo? ¿Qué tormentas son
las que no son tan fáciles de predecir?

```{r}
cbind(fitted(fit_2a,re_formula = NA),fitted(fit_2a1,re_formula = NA))
```


```{r}
loo_2a<-loo(fit_2a) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2a #imprime resultados 
```
```{r}
plot(loo_2a)
```





//////////////////////////////////////////////////////////////////////////

Question: In 2014, a paper was published that was entitled “Female hurricanes are deadlier than male hurricanes.” As the title suggests, the paper claimed that hurricanes with female names have caused greater loss of life, and the explanation given is that people unconsciously rate female hurricanes as less dangerous and so are less likely to evacuate. Statisticians severely criticized the paper after publication. Here, you’ll explore the complete data used in the paper and consider the hypothesis that hurricanes with female names are deadlier. Load the data with:

Acquaint yourself with the columns by inspecting the help ?Hurricanes. In this problem, you’ll focus on predicting deaths using femininity of each hurricane’s name.

Fit and interpret the simplest possible model, a Poisson model of deaths using femininity as a predictor. You can use quap or ulam. Compare the model to an intercept-only Poisson model of deaths. How strong is the association between femininity of name and deaths? Which storms does the model fit (retrodict) well? Which storms does it fit poorly?

Answer: First, let’s prepare the data:

```{r, message=FALSE, cache = TRUE}
d <- Hurricanes # load data on object called d
d$fem_std <- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity
dat <- list(D = d$deaths, F = d$fem_std)
```

Now that we have standardised data for the feminity of our hurricane names which makes priors easier to formulate, we can specify our initial model idea:

```{r, message=FALSE, cache = TRUE}
# model formula
f <- alist(
  D ~ dpois(lambda), # poisson outcome distribution
  log(lambda) <- a + bF * F, # log-link for lambda with linear model
  # priors in log-space, 0 corresponds to outcome of 1
  a ~ dnorm(1, 1),
  bF ~ dnorm(0, 1)
)
```

But are these priors any good? Let’s simulate them why don’t we:

```{r, message=FALSE, cache = TRUE}
N <- 1e3
a <- rnorm(N, 1, 1)
bF <- rnorm(N, 0, 1)
F_seq <- seq(from = -2, to = 2, length.out = 30) # sequence from -2 to 2 because femininity data is standardised
plot(NULL,
  xlim = c(-2, 2), ylim = c(0, 500),
  xlab = "name femininity (std)", ylab = "deaths"
)
for (i in 1:N) {
  lines(F_seq,
    exp(a[i] + bF[i] * F_seq), # inverse link to get outcome scale
    col = grau(), lwd = 1.5
  )
}
```

I’d think that’s pretty alright. We allow for both positive and negative trends between death toll and femininity of hurricane name, but don’t have a lot of explosive trends in our priors. These strong trends are quite unintuitive. Our vast majority of trends however are very ambiguous and so I proceed with these priors and run the model:

```{r, message=FALSE, cache = TRUE}
mH1 <- ulam(f, data = dat, chains = 4, cores = 4, log_lik = TRUE)
precis(mH1)
```

So according to this, there is a positive relationship between hurricane name femininity and death toll. Which hurricanes do we actually retrodict well, though? Let’s plot, this:

```{r, message=FALSE, cache = TRUE}
# plot raw data
plot(dat$F, dat$D,
  pch = 16, lwd = 2,
  col = rangi2, xlab = "femininity (std)", ylab = "deaths"
)
# compute model-based trend
pred_dat <- list(F = seq(from = -2, to = 2, length.out = 1e2))
lambda <- link(mH1, data = pred_dat) # predict deaths
lambda.mu <- apply(lambda, 2, mean) # get mean prediction
lambda.PI <- apply(lambda, 2, PI) # get prediction interval
# superimpose trend
lines(pred_dat$F, lambda.mu)
shade(lambda.PI, pred_dat$F)
# compute sampling distribution
deaths_sim <- sim(mH1, data = pred_dat) # simulate posterior observations
deaths_sim.PI <- apply(deaths_sim, 2, PI) # get simulation interval
# superimpose sampling interval as dashed lines
lines(pred_dat$F, deaths_sim.PI[1, ], lty = 2)
lines(pred_dat$F, deaths_sim.PI[2, ], lty = 2)
```


Ok. There is quite a bit to unpack here. First of all, our model does not retrodict many of the hurricanes well even though it is quite certain of its predictions (grey shaded area which is hardly visible). Quite obviously, this model misses many of the hurricane death tolls to the right hand side of the above plot. This is a clear sign of over-dispersion which our model failed to account for. The weak, positive trend we are seeing here seems to be informed largely by these highly influential data points. We can assess whether and how influential some data points are with the Paraeto-K values (anything above 1 indicates an influential data point) following:

```{r, message=FALSE, cache = TRUE}
ggplot(as.data.frame(PSISk(mH1)), aes(x = PSISk(mH1))) +
  stat_halfeye() +
  theme_bw() +
  labs(title = "Paraeto-K values", subtitle = "Values > 1 indicate highly influential data")

```

Boy! Some hurricanes really do drive our model to a big extent!

//////////////////////////////////////////////////////////////////////////

## `r colorize("Inciso  **2.b**", subtitle=TRUE)`

Los conteos casi siempre están demasiado dispersos en relación con una
distribución Poisson. Así que ajusta un Modelo gamma-Poisson (también conocido
como binomial-negativo) para predecir muertes utilizando la feminidad. Demuestra
que el modelo con sobre-dispersión ya no muestra un resultado positivo tan
preciso entre feminidad y muerte, con un intervalo de 89% que se superpone cero.
¿Puedes explicar por qué la asociación disminuyó?

## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

```{r}
fit_2b<-brm(data=huracanes,
            family=negbinomial,
            deaths~ 1 + feminidad.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2b")

summary(fit_2b, digits = 2)
```


```{r}
prior_summary(fit_2b)
```


```{r}
loo_2b<-loo(fit_2b) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2b #imprime resultados 
```

```{r}
plot(loo_2a)
```


```{r}
plot(loo_2b)
```

```{r}
plot(conditional_effects(fit_2b, effects = "feminidad.centrada"))
```
```{r}
plot(conditional_effects(fit_2a, effects = "feminidad.centrada"))
```



```{r}
plot(fit_2b)
```

```{r}
plot(fit_2a)
```

```{r, message=FALSE, cache = TRUE}
comparativo_diff_loo_2b<-loo_compare(loo_2a,loo_2b) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_2b #imprime comparativo
```

```{r}
comparativo_loo_2b<-cbind(loo_2a,loo_2b) #guarda comparativo
comparativo_loo_2b
```

El Modelo gamma-Poisson (también conocido como binomial-negativo). Utiliza una distribución gamma que permite calcular una tasa de mortalidad para cada resultado individual de la feminidad.centrada en lugar de una tasa de mortalidad general como la Poisson. Al tener la gamma dos parámetros, implica que tiene información sobre la variabilidad de los datos, mientras que la Poisson tiene información de la media y la varianza en un solo parámetro. Esto relaja la distribución Gamma y nos da una información posterior más amplia, pero le implica a mis datos tener que dar más información sobre la media y la varianza. Al tener pocos datos la asociación se complica utilizando la binomial negativa.

/////////////////////////////////////////////////////////////////////////
Question: Counts are nearly always over-dispersed relative to Poisson. So fit a gamma-Poisson (aka negative-binomial) model to predict deaths using femininity. Show that the over-dispersed model no longer shows as precise a positive association between femininity and deaths, with an 89% interval that overlaps zero. Can you explain why the association diminished in strength?

Answer: To start this off, I load the library and data again, so much of the exercise and my solutions can stand by itself:

```{r, message=FALSE, cache = TRUE}
d <- Hurricanes # load data on object called d
d$fem_std <- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity
dat <- list(D = d$deaths, F = d$fem_std)
```

Again, with the data prepared, we fit our model - the same model as before just with a different outcome distribution:

```{r, message=FALSE, cache = TRUE}
mH2 <- ulam(
  alist(
    D ~ dgampois(lambda, scale),
    log(lambda) <- a + bF * F,
    a ~ dnorm(1, 1),
    bF ~ dnorm(0, 1),
    scale ~ dexp(1) # strictly positive hence why exponential prior
  ),
  data = dat, chains = 4, cores = 4, log_lik = TRUE
)
precis(mH2)
```

Cool. Our previously identified positive relationship between standardised femininity of hurricane name and death toll is still there albeit slightly diminished in magnitude. However, the credible interval around it has widened considerably and overlaps zero now.

Let’s compare the estimates of our models side by side:

```{r, message=FALSE, cache = TRUE}
plot(coeftab(mH1, mH2))
```

These shows quite clearly how our new model is much more uncertain of the parameters.

So what about the predictions of this new model? I plot them the exact same way as previously:

```{r, message=FALSE, cache = TRUE}
# plot raw data
plot(dat$F, dat$D,
  pch = 16, lwd = 2,
  col = rangi2, xlab = "femininity (std)", ylab = "deaths"
)
# compute model-based trend
pred_dat <- list(F = seq(from = -2, to = 2, length.out = 1e2))
lambda <- link(mH2, data = pred_dat)
lambda.mu <- apply(lambda, 2, mean)
lambda.PI <- apply(lambda, 2, PI)
# superimpose trend
lines(pred_dat$F, lambda.mu)
shade(lambda.PI, pred_dat$F)
# compute sampling distribution
deaths_sim <- sim(mH2, data = pred_dat)
deaths_sim.PI <- apply(deaths_sim, 2, PI)
# superimpose sampling interval as dashed lines
lines(pred_dat$F, deaths_sim.PI[1, ], lty = 2)
lines(pred_dat$F, deaths_sim.PI[2, ], lty = 2)
```

What’s there left to say other than: “Look at that increased uncertainty of our model” at this point? Well, we can talk about the accuracy of our predictions. They still blow. The uncertainty of our model is nice and all, but with a predictive accuracy like this why would we trust the model?

For now, let’s turn to the conceptual part of this exercise: “Why has the association diminished with the new model?” The question comes down to understanding what the gamma distribution does to our model. The gamma distribution allows for a death rate to be calculated for each outcome individually rather than one overall death rate for all hurricanes. These individual rates are sampled from a common distribution which is a function of the femininity of hurricane names. As a matter of fact, we can plot this:

```{r, message=FALSE, cache = TRUE}
post <- extract.samples(mH2)
par(mfrow = c(1, 3))
for (fem in -1:1) {
  for (i in 1:1e2) {
    curve(dgamma2(
      x, # where to calculate density
      exp(post$a[i] + post$bF[i] * fem), # linear model with inverse link applied
      post$scale[i] # scale for gamma
    ),
    from = 0, to = 70, xlab = "mean deaths", ylab = "Density",
    ylim = c(0, 0.19), col = col.alpha("black", 0.2),
    add = ifelse(i == 1, FALSE, TRUE)
    )
  }
  mtext(concat("femininity  =   ", fem))
}
```

These are the gamma distributions samples from the posterior distribution of death rates when assuming same femininity of name for all of them at three different levels of femininity. Yes, a distribution sampled from another distribution. The above plots simply show the uncertainty of which gamma distribution to settle on.

Since our model and gamma distributions are informed by a, bF, and the scale for the gamma distribution at the same time many combinations of a and bF are consistent with the data which results in a wider posterior distribution.

Finally, let’s look at Paraeto-K values and potentially influential data again:

```{r, message=FALSE, cache = TRUE}
ggplot(as.data.frame(PSISk(mH2)), aes(x = PSISk(mH2))) +
  stat_halfeye() +
  theme_bw() +
  labs(title = "Paraeto-K values", subtitle = "Values > 1 indicate highly influential data")
```

MUCH BETTER than before!


/////////////////////////////////////////////////////////////////////////

## `r colorize("Inciso  **2.c**", subtitle=TRUE)`

En los datos, hay dos medidas del potencial de letalidad de un huracán:
`damage_norm` y `min_pressure`. Consulta `?Hurricanes`. Hace algo de sentido
imaginar que la feminidad de un nombre importa más cuando el huracán es en sí
mismo es mortal. Esto implica una interacción entre la feminidad y posiblemente una
o las dos `damage_norm` y `min_pressure`. Ajusta una serie de modelos evaluando
estas interacciones. Interpreta y compara los modelos. Al interpretar las
estimaciones, te puede ayudar a generar predicciones que contrasten los
huracanes con nombres masculinos y femeninos. ¿Son probables los coeficientes?

## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

```{r}
feminidad.std<-as.data.frame(scale(huracanes$femininity,scale = TRUE)) #centramos feminidad alrededor de su media
colnames(feminidad.std)<-c("feminidad.std") #la nombramos feminidad.centrada
dano.std<-as.data.frame(scale(huracanes$damage_norm,scale = TRUE)) #centramos feminidad alrededor de su media
colnames(dano.std)<-c("dano.std") #la nombramos feminidad.centrada
presion.std<-as.data.frame(scale(huracanes$min_pressure,scale=TRUE)) #centramos feminidad alrededor de su media
colnames(presion.std)<-c("presion.std") #la nombramos feminidad.centrada
huracanes<-cbind(huracanes,feminidad.std,dano.std,presion.std) #integramos las variables en menores.edad

head(huracanes) #imprimimos las primeras observaciones
```



```{r}
fit_2c_fd_negbin<-brm(data=huracanes,
            family=negbinomial,
             deaths~ 1 + feminidad.std +dano.std+feminidad.std*dano.std,
            # +feminidad.centrada*dano.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2c_fd_negbin")

summary(fit_2c_fd_negbin, digits = 2)
```

```{r}
loo_2c_fd_negbin<-loo(fit_2c_fd_negbin) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2c_fd_negbin  #imprime resultados
```

```{r}
plot(fit_2c_fd_negbin,pars=c("feminidad.std","dano.std"))
```



```{r}
fit_2c_fd_poi<-brm(data=huracanes,
            family=poisson,
             deaths~ 1 + feminidad.std +dano.std+feminidad.std*dano.std,
            # +feminidad.centrada*dano.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2c_fd_poi")

summary(fit_2c_fd_poi, digits = 2)
```


```{r}
loo_2c_fd_poi<-loo(fit_2c_fd_poi) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2c_fd_poi  #imprime resultados
```

```{r}
fit_2c_fp_negbin<-brm(data=huracanes,
            family=negbinomial,
             deaths~ 1 + feminidad.std +presion.std+feminidad.std*presion.std,
            # +feminidad.centrada*dano.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2c_fp_negbin")

summary(fit_2c_fp_negbin, digits = 2)
```

```{r}
loo_2c_fp_negbin<-loo(fit_2c_fp_negbin) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2c_fp_negbin  #imprime resultados
```


```{r}
fit_2c_fp_poi<-brm(data=huracanes,
            family=poisson,
             deaths~ 1 + feminidad.std +presion.std+feminidad.std*presion.std,
            # +feminidad.centrada*dano.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2c_fp_poi")

summary(fit_2c_fp_poi, digits = 2)
```

```{r}
loo_2c_fp_poi<-loo(fit_2c_fp_poi) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2c_fp_poi  #imprime resultados
```

```{r}
fit_2c_fpd_negbin<-brm(data=huracanes,
            family=negbinomial,
             deaths~ 1 + feminidad.std+presion.std+dano.std+feminidad.std*presion.std+feminidad.std*dano.std,
            # +feminidad.centrada*dano.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2c_fpd_negbin")

summary(fit_2c_fpd_negbin, digits = 2)
```


```{r}
loo_2c_fpd_negbin<-loo(fit_2c_fpd_negbin) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2c_fpd_negbin  #imprime resultados
```

```{r}
fit_2c_fpd_poi<-brm(data=huracanes,
            family=poisson,
             deaths~ 1 + feminidad.std+presion.std+dano.std+feminidad.std*presion.std+feminidad.std*dano.std,
            # +feminidad.centrada*dano.centrada,
            seed=SEED,
            sample_prior = T,
            file="fits/huracanes.fit2c_fpd_poi")

summary(fit_2c_fpd_poi, digits = 2)
```

```{r}
loo_2c_fpd_poi<-loo(fit_2c_fpd_poi) #calcula: elpd_loo que corresponde a la log-densidad; p_loo: el número efectivo de parámetros; looic: la devianza del modelo así como suss errores estándar (SE) variando sobre todas las observaciones con validación cruzada
loo_2c_fpd_poi  #imprime resultados
```


El diagnóstico de todos los modelos que loo arrojó es que son buenos: "All Pareto k estimates are good (k < 0.5)." sólo con excepción del que utiliza un polinomio grado 6 en términos la edad.centrada como predictores pues en este caso indica ok: "All Pareto k estimates are ok (k < 0.7).". A continuación mostramos un resumen de los estadísticos de todos los modelos con loo:

```{r}
comparativo_loo_2c<-cbind(loo_2c_fd_negbin,loo_2c_fd_poi,loo_2c_fp_negbin,loo_2c_fp_poi,loo_2c_fpd_negbin,loo_2c_fpd_poi) #guarda comparativo
comparativo_loo_2c #imprime comparativo de modelos
```

En términos de la devianza (looic) los modelos binomiales negativos tienen la mejor capacidad predictiva ya que tienen una menor devianza respecto a los modelos Poisson, cuya devianza está en términos de millares. El mejor modelo, fue el que incluye las 2 interacciones con la feminidad.std, que son feminidad.std:dano.std y feminidad.std:presion.std

Además, notamos que el error estándar de looic es de 33 aproximadamente en estos mismos modelos, por lo que no podríamos dar una conclusión definitiva sobre cuál de estos 3 predictores es el mejor con este criterio.

Para complementar el análisis, procederemos a obtener un comparativo en términos de la log-densidad predictiva con el método loo_compare().

```{r}
comparativo_diff_loo_2c<-loo_compare(loo_2c_fd_negbin,loo_2c_fd_poi,loo_2c_fp_negbin,loo_2c_fp_poi,loo_2c_fpd_negbin,loo_2c_fpd_poi) #calcula comparativo de diferencia en términos de la log-densidad predictiva y un error estándar sobre esta diferencia (se_diff). Ordenando los modelos del mejor al peor
comparativo_diff_loo_2c  #imprime comparativo de modelos
```

De lo anterior, concluimos que la capacidad predictiva de los modelos con polinomios de mayor grado (4-6) no tiene una diferencia lo suficientemente fuerte y por tanto, escogemos como el mejor modelo como fit_2c_fd_negbin que incorpora como predictores a la feminidad.std y dano.std por el principio de parsimonia.


```{r}
dano_seq <- seq(from = -1, to = 5.5, length.out = 1e2) # Secuencia para daños
# 'masculine' storms
dano_pred_f <- data.frame(female = -1, D = dano_seq)
head(dano_pred_f)
```

```{r}
#femenino
dano_pred_m <- data.frame(female = 1, D = dano_seq)
head(dano_pred_m)
```

```{r}
lambda_f <- link(fit_2c_fd_negbin, data = dano_pred_f)
```

```{r}
lambda_m <- link(fit_2c_fd_negbin, data = dano_pred_m)
```

```{r}
lambda_m.mu <- apply(lambda_m, 2, mean)
lambda_m.PI <- apply(lambda_m, 2, PI)
```

```{r}
lambda_f.mu <- apply(lambda_f, 2, mean)
lambda_f.PI <- apply(lambda_f, 2, PI)
```




```{r}
pred(fit_2c_fpd_negbin)
```


/////////////////////////////////////////////////////////////////////////
Question: In order to infer a strong association between deaths and femininity, it’s necessary to include an interaction effect. In the data, there are two measures of a hurricane’s potential to cause death: damage_norm and min_pressure. Consult ?Hurricanes for their meanings. It makes some sense to imagine that femininity of a name matters more when the hurricane is itself deadly. This implies an interaction between femininity and either or both of damage_norm and min_pressure. Fit a series of models evaluating these interactions. Interpret and compare the models. In interpreting the estimates, it may help to generate counterfactual predictions contrasting hurricanes with masculine and feminine names. Are the effect sizes plausible?

Answer: To start this off, I load the library and data again, so much of the exercise and my solutions can stand by itself:

```{r, message=FALSE, cache = TRUE}
d <- Hurricanes # load data on object called d
d$fem_std <- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity
dat <- list(D = d$deaths, F = d$fem_std)
dat$P <- standardize(d$min_pressure)
dat$S <- standardize(d$damage_norm)
```

The data is ready and I step into my model fitting procedure. Here, I start with a basic model which builds on the previous gamma-Poisson model by adding an interaction between femininity and min_pressure:

```{r, message=FALSE, cache = TRUE}
mH3a <- ulam(
  alist(
    D ~ dgampois(lambda, scale),
    log(lambda) <- a + bF * F + bP * P + bFP * F * P,
    a ~ dnorm(1, 1),
    c(bF, bP, bFP) ~ dnorm(0, 1),
    scale ~ dexp(1)
  ),
  data = dat, cores = 4, chains = 4, log_lik = TRUE
)
precis(mH3a)
```

As minimum pressure gets lower, a storm grows stronger (I was confused by that myself when answering these exercises). Quite obviously, the lower the pressure in a storm, the more severe the storm, and the more people die which is reflected by the negative value in bP. bF is still estimated to be positive. This time, the interval doesn’t even overlap zero. Meanwhile, the interaction effect bFP is positive. I find it hard to interpret this so I’d rather plot some predictions against real data:

```{r, message=FALSE, cache = TRUE}
P_seq <- seq(from = -3, to = 2, length.out = 1e2) # pressure sequence
# 'masculine' storms
d_pred <- data.frame(F = -1, P = P_seq)
lambda_m <- link(mH3a, data = d_pred)
lambda_m.mu <- apply(lambda_m, 2, mean)
lambda_m.PI <- apply(lambda_m, 2, PI)
# 'feminine' storms
d_pred <- data.frame(F = 1, P = P_seq)
lambda_f <- link(mH3a, data = d_pred)
lambda_f.mu <- apply(lambda_f, 2, mean)
lambda_f.PI <- apply(lambda_f, 2, PI)
# Plotting, sqrt() to make differences easier to spot, can't use log because there are storm with zero deaths
plot(dat$P, sqrt(dat$D),
  pch = 1, lwd = 2, col = ifelse(dat$F > 0, "red", "dark gray"),
  xlab = "minimum pressure (std)", ylab = "sqrt(deaths)"
)
lines(P_seq, sqrt(lambda_m.mu), lty = 2)
shade(sqrt(lambda_m.PI), P_seq)
lines(P_seq, sqrt(lambda_f.mu), lty = 1, col = "red")
shade(sqrt(lambda_f.PI), P_seq, col = col.alpha("red", 0.2))
```

Our model expects masculine (grey) storms to be less deadly, on average, than feminine (red) ones. As pressure drops (toward the rightward side of the plot above), these differences become smaller and smaller. Quite evidently, some of these storms are influencing what our model predicts much more so than others:

```{r, message=FALSE, cache = TRUE}
ggplot(as.data.frame(PSISk(mH3a)), aes(x = PSISk(mH3a))) +
  stat_halfeye() +
  theme_bw() +
  labs(title = "Paraeto-K values", subtitle = "Values > 1 indicate highly influential data")
```

Let’s turn to the second variable we may want to add damage_norm - the damage caused by each storm:

```{r, message=FALSE, cache = TRUE}
mH3b <- ulam(
  alist(
    D ~ dgampois(lambda, scale),
    log(lambda) <- a + bF * F + bS * S + bFS * F * S,
    a ~ dnorm(1, 1),
    c(bF, bS, bFS) ~ dnorm(0, 1),
    scale ~ dexp(1)
  ),
  data = dat, chains = 4, cores = 4, log_lik = TRUE
)
precis(mH3b)
```

That just eradicated the effect of femininity of hurricane name (bF)! The newly added interaction parameter bFS is incredibly strong and positive. Again, let’s visualise this:

```{r, message=FALSE, cache = TRUE}
S_seq <- seq(from = -1, to = 5.5, length.out = 1e2) # damage sequence
# 'masculine' storms
d_pred <- data.frame(F = -1, S = S_seq)
lambda_m <- link(mH3b, data = d_pred)
lambda_m.mu <- apply(lambda_m, 2, mean)
lambda_m.PI <- apply(lambda_m, 2, PI)
# 'feminine' storms
d_pred <- data.frame(F = 1, S = S_seq)
lambda_f <- link(mH3b, data = d_pred)
lambda_f.mu <- apply(lambda_f, 2, mean)
lambda_f.PI <- apply(lambda_f, 2, PI)
# plot
plot(dat$S, sqrt(dat$D),
  pch = 1, lwd = 2, col = ifelse(dat$F > 0, "red", "dark gray"),
  xlab = "normalized damage (std)", ylab = "sqrt(deaths)"
)
lines(S_seq, sqrt(lambda_m.mu), lty = 2)
shade(sqrt(lambda_m.PI), S_seq)
lines(S_seq, sqrt(lambda_f.mu), lty = 1, col = "red")
shade(sqrt(lambda_f.PI), S_seq, col = col.alpha("red", 0.2))
```

We can clearly see how our model makes less of a distinction between masculine and feminine hurricanes overall at this point. Damage norm scales multiplicatively. The distances grow fast as we approach the rightward side of the plot. This is difficult for the model to account for. Hence why the model is underwhelming.

So why is the interaction effect so strong? Probably because of those 3-4 highly influential feminine storms at the upper-righthand corner of our plot above which implies that feminine storms are especially deadly when they are damaging to begin with. Personally, I don’t trust this association and would argue that there is no logical reason for it and most likely an artefact of the limited data availability.


////////////////////////////////////////////////////////////////////////

## `r colorize("Inciso  **2.d**", subtitle=TRUE)`

En el artículo original sobre huracanes, se utilizó directamente el daño por
tormenta (`damage_norm`). Esta suposición implica que la mortalidad aumenta
exponencialmente con aumento lineal en la fuerza de la tormenta. Esto debido a
que en regresión Poisson usamos un enlace logarítmico. Entonces, vale la pena
explorar una hipótesis alternativa: que el logaritmo de la fuerza de la tormenta
es lo que importa. Explora esto usando el logaritmo de `damage_norm` como un
predictor. Usando la mejor estructura de modelo del inciso anterior, compara un
modelo que usa `log(damage_norm)` a un modelo que usa `damage_norm`
directamente. Compara la capacidad predictiva, así como sus predicciones
implícitas. ¿Qué es lo que concluyes?

## `r colorize("Respuesta", subtitle=TRUE, color2="Salmon")`

////////////////////////////////////////////////////////////////////////
Question: In the original hurricanes paper, storm damage (damage_norm) was used directly. This assumption implies that mortality increases exponentially with a linear increase in storm strength, because a Poisson regression uses a log link. So it’s worth exploring an alternative hypothesis: that the logarithm of storm strength is what matters. Explore this by using the logarithm of damage_norm as a predictor. Using the best model structure from the previous problem, compare a model that uses log(damage_norm) to a model that uses damage_norm directly. Compare their DIC/WAIC values as well as their implied predictions. What do you conclude?

Answer: To start this off, I load the library and data again, so much of the exercise and my solutions can stand by itself:

```{r, message=FALSE, cache = TRUE}
d <- Hurricanes # load data on object called d
d$fem_std <- (d$femininity - mean(d$femininity)) / sd(d$femininity) # standardised femininity
dat <- list(D = d$deaths, F = d$fem_std)
dat$S2 <- standardize(log(d$damage_norm))
```

Let’s fit the model as before and compare it to the previously identified best model:

```{r, message=FALSE, cache = TRUE}
mH4 <- ulam(
  alist(
    D ~ dgampois(lambda, scale),
    log(lambda) <- a + bF * F + bS * S2 + bFS * F * S2,
    a ~ dnorm(1, 1),
    c(bF, bS, bFS) ~ dnorm(0, 1),
    scale ~ dexp(1)
  ),
  data = dat, chains = 4, cores = 4, log_lik = TRUE
)
compare(mH3b, mH4, func = PSIS)
```

Model mH4 clearly outperforms the earlier (non-logarithmic) model mH3b. How do the parameter estimates look in comparison?

```{r, message=FALSE, cache = TRUE}
plot(coeftab(mH3b, mH4),
  labels = paste(rep(rownames(coeftab(mH3b, mH4)@coefs), each = 2),
    rep(c("Norm", "Log"), nrow(coeftab(mH3b, mH4)@coefs) * 2),
    sep = "-"
  )
)
```

With the log-transformed input, bFS has increased in magnitude. What do the resulting predictions look like?

```{r, message=FALSE, cache = TRUE}
S2_seq <- seq(from = -3, to = 1.8, length.out = 1e2)
# 'masculine' storms
d_pred <- data.frame(F = -1, S2 = S2_seq)
lambda_m <- link(mH4, data = d_pred)
lambda_m.mu <- apply(lambda_m, 2, mean)
lambda_m.PI <- apply(lambda_m, 2, PI)
# 'feminine' storms
d_pred <- data.frame(F = 1, S2 = S2_seq)
lambda_f <- link(mH4, data = d_pred)
lambda_f.mu <- apply(lambda_f, 2, mean)
lambda_f.PI <- apply(lambda_f, 2, PI)
# plot
plot(dat$S2, sqrt(dat$D),
  pch = 1, lwd = 2, col = ifelse(dat$F > 0, "red", "dark gray"),
  xlab = "normalized damage (std)", ylab = "sqrt(deaths)"
)
lines(S2_seq, sqrt(lambda_m.mu), lty = 2)
shade(sqrt(lambda_m.PI), S2_seq)
lines(S2_seq, sqrt(lambda_f.mu), lty = 1, col = "red")
shade(sqrt(lambda_f.PI), S2_seq, col = col.alpha("red", 0.2))

```

Now this model fits the data much better! Still not perfect, but much better.

/////////////////////////////////////////////////////////////////////////


`r col_square("**3.** Inferencia Causal: experimentos aleatorizados")`

Distribuciones muestrales bajo aleatorización: Utilice la covariable y el
potencial de salida (*potential outcome*) de los datos en la tabla 18.1 del
libro *Regresion and Other Stories*. Abajo viene una versión simplificada
(aunque hacen falta un par más, incorporalas):

```{r, warning=FALSE, message=FALSE, cache = TRUE}

omega <- tibble(female = factor(rep(rep(c(1,0), each = 2), 2)), 
       age        = rep(c(4,5,6,7), each = 2) * 10, 
       treatment  = factor(rep(c(0,1), each = 4)), 
       treatment_r= factor(c(0,1,0,1,0,1,0,1)),
       pot_out_z0 = rep(c(140, 150, 160, 170), each = 2),
       pot_out_z1 = rep(c(135, 140, 155, 160), each = 2),
       outcome    = rep(c(140, 150, 155, 160), each = 2))

omega %>%
  kbl(digits=2, format.args = list(big.mark = ","))  %>%
  kable_styling(bootstrap_options = "striped", full_width = F)

```

```{r, warning=FALSE, message=FALSE, cache = TRUE}
lm(outcome ~ treatment_r, omega)
```

```{r, warning=FALSE, message=FALSE, cache = TRUE}
x<-factor(c(0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1))
y<-c(140,140,150,150,160,160,170,170,135,135,140,140,155,155,160,160)
lm(y ~ x)
```

```{r, warning=FALSE, message=FALSE, cache = TRUE}
efec<-function(){
  x1<-sample(c(0,0,0,0,1,1,1,1),8)
  x2<-(x1+1) %% 2
  y1<-c(140,140,150,150,160,160,170,170)
  y2<-c(135,135,140,140,155,155,160,160)
  return((x2%*%y2 - x1%*%y1)/4)
}
mean(rerun(10000,efec()) %>% flatten_dbl())

```


como punto de partida para considerar distribuciones de aleatorización de cuatro
diseños diferentes mediante la creación de simulaciones en `R`.

Comenta sobre el sesgo relativo y la eficiencia para cada uno de los siguientes
diseños:
• Diseño completamente aleatorizado,
• Diseño aleatorio usando bloques por los cuatro participantes mayores frente a
los cuatro más jóvenes,
• Diseño de pares combinados,

utilizando cada una de las siguientes estimaciones:
• Diferencia de medias,
• Regresión del indicador de tratamiento y la edad,
• Regresión del indicador de tratamiento, edad y sexo,
• Regresión del indicador de tratamiento, edad, sexo e interacción tratamiento
$\times$ sexo.


`r col_square("**4.** Inferencia Causal y Modelos de Regresión: vacas")`

*Aleatorización desordenada*: los datos de `vacas.txt` contiene datos de un
experimento que se llevó a cabo con 50 vacas para estimar el efecto de un
complemento alimenticio en 6 resultados relacionados con la cantidad de grasa
láctea producida por cada vaca. Se consideraron cuatro dietas (tratamientos),
correspondientes a diferentes niveles del complemento, y se registraron tres
variables antes de la asignación del tratamiento: número de lactancia
(temporadas de lactancia), edad y peso inicial de la vaca.

Las vacas se asignaron inicialmente a tratamientos completamente al azar, y
después se revisaron las distribuciones de las tres covariables para verificar
el equilibrio a lo largo de los grupos de tratamiento. Se probaron varias
aleatorizaciones, y la que produjo el "mejor" equilibrio con respecto a las tres
covariables fue la que se escogió. El tratamiento depende sólo de las
covariables completamente observadas y no de las no registradas como el aspecto
físico de las vacas o los momentos en los que vacas entraron en el estudio. Esto
es porque las decisiones de volver a aleatorizar no son explicados.
Consideraremos diferentes estimaciones del efecto del complemento en la grasa
láctea media diaria producida.

## `r colorize("Inciso  **4.a**", subtitle=TRUE)`

Considera la regresión massimple de la grasa láctea media diaria con el nivel
de complemento. Calcula el efecto del tratamiento estimado (coeficiente de
regresión) y el error estándar, y explica por qué este no es un análisis
completamente apropiado dada la aleatorización utilizada.

## `r colorize("Inciso  **4.b**", subtitle=TRUE)`

Agrega más predictores al modelo. Explica el razonamiento para la elección de
covariables en el modelo. Compare el efecto estimado del tratamiento con el
resultado de (a).

## `r colorize("Inciso  **4.c**", subtitle=TRUE)`

Repite (**`r colorize("4. b", "#00614E")`**), esta vez considerando el nivel del complemento como un predictor
categórico con cuatro niveles. Haga una gráfica que muestre la estimación (y el
error estándar) del efecto del tratamiento en cada nivel, y también mostrando la
inferencia del modelo ajustado en (**`r colorize("4. b", "#00614E")`**).


```{r, warning=FALSE, message=FALSE, cache = TRUE}
Vacas <- read_delim("vacas.txt", delim = " ") %>%
  type.convert() %>%
  as.data.frame()

# CHECAR SI SE PUEDE EVITAR CREAR ATRIBUTOS Y/O SI ES NECESARIO ELMINARLOS
attr(Vacas, 'problems') <- NULL
attr(Vacas, 'spec') <- NULL
Vacas<-as.tibble(Vacas)

Vacas %>%
  head() %>%
  kbl(digits=2, format.args = list(big.mark = ","))  %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
  # kable_material(c("striped"))
```

```{r, warning=FALSE, message=FALSE, cache = TRUE}
descr(Vacas) %>%
  kbl(digits=2, format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

```{r, warning=FALSE, message=FALSE, cache = TRUE, results='asis'}
# Si se quisiera visualizar el summary corriendo solo este chunck hacerlo con:
# print(dfSummary(Vacas, plain.ascii=FALSE, style="grid", valid.col=FALSE), method="render")

# Con lo sisuientes parámetros (incluido la opción del chunk "results='asis'", puede
# visualizarse el summary cuando se genera el html)
dfSummary(Vacas, plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, valid.col = TRUE, tmp.img.dir = "/tmp")
```


